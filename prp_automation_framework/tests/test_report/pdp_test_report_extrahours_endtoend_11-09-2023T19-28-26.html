<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <title>PDP ExtraHours Report</title>
    <style>body {
  font-family: Helvetica, Arial, sans-serif;
  font-size: 12px;
  /* do not increase min-width as some may use split screens */
  min-width: 800px;
  color: #999;
}

h1 {
  font-size: 24px;
  color: black;
}

h2 {
  font-size: 16px;
  color: black;
}

p {
  color: black;
}

a {
  color: #999;
}

table {
  border-collapse: collapse;
}

/******************************
 * SUMMARY INFORMATION
 ******************************/
#environment td {
  padding: 5px;
  border: 1px solid #E6E6E6;
}
#environment tr:nth-child(odd) {
  background-color: #f6f6f6;
}

/******************************
 * TEST RESULT COLORS
 ******************************/
span.passed,
.passed .col-result {
  color: green;
}

span.skipped,
span.xfailed,
span.rerun,
.skipped .col-result,
.xfailed .col-result,
.rerun .col-result {
  color: orange;
}

span.error,
span.failed,
span.xpassed,
.error .col-result,
.failed .col-result,
.xpassed .col-result {
  color: red;
}

/******************************
 * RESULTS TABLE
 *
 * 1. Table Layout
 * 2. Extra
 * 3. Sorting items
 *
 ******************************/
/*------------------
 * 1. Table Layout
 *------------------*/
#results-table {
  border: 1px solid #e6e6e6;
  color: #999;
  font-size: 12px;
  width: 100%;
}
#results-table th,
#results-table td {
  padding: 5px;
  border: 1px solid #E6E6E6;
  text-align: left;
}
#results-table th {
  font-weight: bold;
}

/*------------------
 * 2. Extra
 *------------------*/
.log {
  background-color: #e6e6e6;
  border: 1px solid #e6e6e6;
  color: black;
  display: block;
  font-family: "Courier New", Courier, monospace;
  height: 230px;
  overflow-y: scroll;
  padding: 5px;
  white-space: pre-wrap;
}
.log:only-child {
  height: inherit;
}

div.image {
  border: 1px solid #e6e6e6;
  float: right;
  height: 240px;
  margin-left: 5px;
  overflow: hidden;
  width: 320px;
}
div.image img {
  width: 320px;
}

div.video {
  border: 1px solid #e6e6e6;
  float: right;
  height: 240px;
  margin-left: 5px;
  overflow: hidden;
  width: 320px;
}
div.video video {
  overflow: hidden;
  width: 320px;
  height: 240px;
}

.collapsed {
  display: none;
}

.expander::after {
  content: " (show details)";
  color: #BBB;
  font-style: italic;
  cursor: pointer;
}

.collapser::after {
  content: " (hide details)";
  color: #BBB;
  font-style: italic;
  cursor: pointer;
}

/*------------------
 * 3. Sorting items
 *------------------*/
.sortable {
  cursor: pointer;
}

.sort-icon {
  font-size: 0px;
  float: left;
  margin-right: 5px;
  margin-top: 5px;
  /*triangle*/
  width: 0;
  height: 0;
  border-left: 8px solid transparent;
  border-right: 8px solid transparent;
}
.inactive .sort-icon {
  /*finish triangle*/
  border-top: 8px solid #E6E6E6;
}
.asc.active .sort-icon {
  /*finish triangle*/
  border-bottom: 8px solid #999;
}
.desc.active .sort-icon {
  /*finish triangle*/
  border-top: 8px solid #999;
}
</style></head>
  <body onLoad="init()">
    <script>/* This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this file,
 * You can obtain one at http://mozilla.org/MPL/2.0/. */


function toArray(iter) {
    if (iter === null) {
        return null;
    }
    return Array.prototype.slice.call(iter);
}

function find(selector, elem) { // eslint-disable-line no-redeclare
    if (!elem) {
        elem = document;
    }
    return elem.querySelector(selector);
}

function findAll(selector, elem) {
    if (!elem) {
        elem = document;
    }
    return toArray(elem.querySelectorAll(selector));
}

function sortColumn(elem) {
    toggleSortStates(elem);
    const colIndex = toArray(elem.parentNode.childNodes).indexOf(elem);
    let key;
    if (elem.classList.contains('result')) {
        key = keyResult;
    } else if (elem.classList.contains('links')) {
        key = keyLink;
    } else {
        key = keyAlpha;
    }
    sortTable(elem, key(colIndex));
}

function showAllExtras() { // eslint-disable-line no-unused-vars
    findAll('.col-result').forEach(showExtras);
}

function hideAllExtras() { // eslint-disable-line no-unused-vars
    findAll('.col-result').forEach(hideExtras);
}

function showExtras(colresultElem) {
    const extras = colresultElem.parentNode.nextElementSibling;
    const expandcollapse = colresultElem.firstElementChild;
    extras.classList.remove('collapsed');
    expandcollapse.classList.remove('expander');
    expandcollapse.classList.add('collapser');
}

function hideExtras(colresultElem) {
    const extras = colresultElem.parentNode.nextElementSibling;
    const expandcollapse = colresultElem.firstElementChild;
    extras.classList.add('collapsed');
    expandcollapse.classList.remove('collapser');
    expandcollapse.classList.add('expander');
}

function showFilters() {
    let visibleString = getQueryParameter('visible') || 'all';
    visibleString = visibleString.toLowerCase();
    const checkedItems = visibleString.split(',');

    const filterItems = document.getElementsByClassName('filter');
    for (let i = 0; i < filterItems.length; i++) {
        filterItems[i].hidden = false;

        if (visibleString != 'all') {
            filterItems[i].checked = checkedItems.includes(filterItems[i].getAttribute('data-test-result'));
            filterTable(filterItems[i]);
        }
    }
}

function addCollapse() {
    // Add links for show/hide all
    const resulttable = find('table#results-table');
    const showhideall = document.createElement('p');
    showhideall.innerHTML = '<a href="javascript:showAllExtras()">Show all details</a> / ' +
                            '<a href="javascript:hideAllExtras()">Hide all details</a>';
    resulttable.parentElement.insertBefore(showhideall, resulttable);

    // Add show/hide link to each result
    findAll('.col-result').forEach(function(elem) {
        const collapsed = getQueryParameter('collapsed') || 'Passed';
        const extras = elem.parentNode.nextElementSibling;
        const expandcollapse = document.createElement('span');
        if (extras.classList.contains('collapsed')) {
            expandcollapse.classList.add('expander');
        } else if (collapsed.includes(elem.innerHTML)) {
            extras.classList.add('collapsed');
            expandcollapse.classList.add('expander');
        } else {
            expandcollapse.classList.add('collapser');
        }
        elem.appendChild(expandcollapse);

        elem.addEventListener('click', function(event) {
            if (event.currentTarget.parentNode.nextElementSibling.classList.contains('collapsed')) {
                showExtras(event.currentTarget);
            } else {
                hideExtras(event.currentTarget);
            }
        });
    });
}

function getQueryParameter(name) {
    const match = RegExp('[?&]' + name + '=([^&]*)').exec(window.location.search);
    return match && decodeURIComponent(match[1].replace(/\+/g, ' '));
}

function init () { // eslint-disable-line no-unused-vars
    resetSortHeaders();

    addCollapse();

    showFilters();

    sortColumn(find('.initial-sort'));

    findAll('.sortable').forEach(function(elem) {
        elem.addEventListener('click',
            function() {
                sortColumn(elem);
            }, false);
    });
}

function sortTable(clicked, keyFunc) {
    const rows = findAll('.results-table-row');
    const reversed = !clicked.classList.contains('asc');
    const sortedRows = sort(rows, keyFunc, reversed);
    /* Whole table is removed here because browsers acts much slower
     * when appending existing elements.
     */
    const thead = document.getElementById('results-table-head');
    document.getElementById('results-table').remove();
    const parent = document.createElement('table');
    parent.id = 'results-table';
    parent.appendChild(thead);
    sortedRows.forEach(function(elem) {
        parent.appendChild(elem);
    });
    document.getElementsByTagName('BODY')[0].appendChild(parent);
}

function sort(items, keyFunc, reversed) {
    const sortArray = items.map(function(item, i) {
        return [keyFunc(item), i];
    });

    sortArray.sort(function(a, b) {
        const keyA = a[0];
        const keyB = b[0];

        if (keyA == keyB) return 0;

        if (reversed) {
            return keyA < keyB ? 1 : -1;
        } else {
            return keyA > keyB ? 1 : -1;
        }
    });

    return sortArray.map(function(item) {
        const index = item[1];
        return items[index];
    });
}

function keyAlpha(colIndex) {
    return function(elem) {
        return elem.childNodes[1].childNodes[colIndex].firstChild.data.toLowerCase();
    };
}

function keyLink(colIndex) {
    return function(elem) {
        const dataCell = elem.childNodes[1].childNodes[colIndex].firstChild;
        return dataCell == null ? '' : dataCell.innerText.toLowerCase();
    };
}

function keyResult(colIndex) {
    return function(elem) {
        const strings = ['Error', 'Failed', 'Rerun', 'XFailed', 'XPassed',
            'Skipped', 'Passed'];
        return strings.indexOf(elem.childNodes[1].childNodes[colIndex].firstChild.data);
    };
}

function resetSortHeaders() {
    findAll('.sort-icon').forEach(function(elem) {
        elem.parentNode.removeChild(elem);
    });
    findAll('.sortable').forEach(function(elem) {
        const icon = document.createElement('div');
        icon.className = 'sort-icon';
        icon.textContent = 'vvv';
        elem.insertBefore(icon, elem.firstChild);
        elem.classList.remove('desc', 'active');
        elem.classList.add('asc', 'inactive');
    });
}

function toggleSortStates(elem) {
    //if active, toggle between asc and desc
    if (elem.classList.contains('active')) {
        elem.classList.toggle('asc');
        elem.classList.toggle('desc');
    }

    //if inactive, reset all other functions and add ascending active
    if (elem.classList.contains('inactive')) {
        resetSortHeaders();
        elem.classList.remove('inactive');
        elem.classList.add('active');
    }
}

function isAllRowsHidden(value) {
    return value.hidden == false;
}

function filterTable(elem) { // eslint-disable-line no-unused-vars
    const outcomeAtt = 'data-test-result';
    const outcome = elem.getAttribute(outcomeAtt);
    const classOutcome = outcome + ' results-table-row';
    const outcomeRows = document.getElementsByClassName(classOutcome);

    for(let i = 0; i < outcomeRows.length; i++){
        outcomeRows[i].hidden = !elem.checked;
    }

    const rows = findAll('.results-table-row').filter(isAllRowsHidden);
    const allRowsHidden = rows.length == 0 ? true : false;
    const notFoundMessage = document.getElementById('not-found-message');
    notFoundMessage.hidden = !allRowsHidden;
}
</script>
    <h1>PDP ExtraHours Report</h1>
    <p>Report generated on 11-Sep-2023 at 20:08:17 by <a href="https://pypi.python.org/pypi/pytest-html">pytest-html</a> v3.2.0</p>
    <h2>Summary</h2>This report is generated as part of pdp automation ExtraHours on 2023-09-11 20:08:17.278905
    <p>1 tests ran in 2390.58 seconds. </p>
    <p class="filter" hidden="true">(Un)check the boxes to filter the results.</p><input checked="true" class="filter" data-test-result="passed" disabled="true" hidden="true" name="filter_checkbox" onChange="filterTable(this)" type="checkbox"/><span class="passed">0 passed</span>, <input checked="true" class="filter" data-test-result="skipped" disabled="true" hidden="true" name="filter_checkbox" onChange="filterTable(this)" type="checkbox"/><span class="skipped">0 skipped</span>, <input checked="true" class="filter" data-test-result="failed" hidden="true" name="filter_checkbox" onChange="filterTable(this)" type="checkbox"/><span class="failed">1 failed</span>, <input checked="true" class="filter" data-test-result="error" disabled="true" hidden="true" name="filter_checkbox" onChange="filterTable(this)" type="checkbox"/><span class="error">0 errors</span>, <input checked="true" class="filter" data-test-result="xfailed" disabled="true" hidden="true" name="filter_checkbox" onChange="filterTable(this)" type="checkbox"/><span class="xfailed">0 expected failures</span>, <input checked="true" class="filter" data-test-result="xpassed" disabled="true" hidden="true" name="filter_checkbox" onChange="filterTable(this)" type="checkbox"/><span class="xpassed">0 unexpected passes</span>
    <h2>Results</h2>
    <table id="results-table">
      <thead id="results-table-head">
        <tr>
          <th class="sortable result initial-sort" col="result">Result</th>
          <th class="sortable" col="name">Test</th>
          <th class="sortable" col="duration">Duration</th>
          <th class="sortable links" col="links">Links</th></tr>
        <tr hidden="true" id="not-found-message">
          <th colspan="4">No results found. Try to check the filters</th></tr></thead>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/test_pdp_flow_extrahours.py::test_pdp_flow_all</td>
          <td class="col-duration">2383.62</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw0] win32 -- Python 3.9.13 C:\Users\INE12405137\PycharmProjects\pdp_automation_framework\venv\Scripts\python.exe<br/>[gw0] win32 -- Python 3.9.13 C:\Users\INE12405137\PycharmProjects\pdp_automation_framework\venv\Scripts\python.exe[gw0] win32 -- Python 3.9.13 C:\Users\INE12405137\PycharmProjects\pdp_automation_framework\venv\Scripts\python.exe<br/><br/>query = &quot;SELECT COUNT(*) as count  FROM delta_bronze.prp_extrahoursapi_extrahours WHERE MD_PIPELINE_RUN_ID = &#x27;ad26d9b2-50ab-11ee-91b3-bcf4d42f600c&#x27; limit 1&quot;<br/><br/>    def run_sql_adb(query):<br/>        try:<br/>            azure_details_dict = get_env_vars()<br/>            adb_server_host = azure_details_dict.get(&quot;DATABRICKS_SERVER_HOSTNAME&quot;)<br/>            adb_http_path = azure_details_dict.get(&quot;DATABRICKS_HTTP_PATH&quot;)<br/>            adb_token = azure_details_dict.get(&quot;DATABRICKS_TOKEN&quot;)<br/>        except Exception as e:<br/>            logging.error(f&quot;\tEnvironment credentials are missing - {e}&quot;, exc_info=True)<br/>            raise Exception(f&quot;\tEnvironment credentials are missing - {e}&quot;)<br/>    <br/>        try:<br/>            with sql.connect(server_hostname=adb_server_host,<br/>                             http_path=adb_http_path,<br/>                             access_token=adb_token<br/>                             ) as connection:<br/>    <br/>                with connection.cursor() as cursor:<br/>&gt;                   cursor.execute(query)<br/><br/>..\validations.py:22: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/>..\..\..\pdp_automation_framework\venv\lib\site-packages\databricks\sql\client.py:493: in execute<br/>    execute_response = self.thrift_backend.execute_command(<br/>..\..\..\pdp_automation_framework\venv\lib\site-packages\databricks\sql\thrift_backend.py:875: in execute_command<br/>    return self._handle_execute_response(resp, cursor)<br/>..\..\..\pdp_automation_framework\venv\lib\site-packages\databricks\sql\thrift_backend.py:967: in _handle_execute_response<br/>    final_operation_state = self._wait_until_command_done(<br/>..\..\..\pdp_automation_framework\venv\lib\site-packages\databricks\sql\thrift_backend.py:809: in _wait_until_command_done<br/>    self._check_command_not_in_error_or_closed_state(<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;databricks.sql.thrift_backend.ThriftBackend object at 0x000001B914769640&gt;<br/>op_handle = TOperationHandle(operationId=THandleIdentifier(guid=b&quot;a\xed\xac\x96NJM\xb1\xb3]\xee&#x27;\x16 \\\xce&quot;, secret=b&#x27;rb\xb5.\\{D\xd7\xae\xf0p-H&quot;e\x06&#x27;, executionVersion=None), operationType=0, hasResultSet=True, modifiedRowCount=None)<br/>get_operations_resp = TGetOperationStatusResp(status=TStatus(statusCode=0, infoMessages=None, sqlState=None, errorCode=None, errorMessage=No...1)\n\t... 19 more\n&#x27;, responseValidation=None, idempotencyType=None, statementTimeout=None, statementTimeoutLevel=None)<br/><br/>    def _check_command_not_in_error_or_closed_state(<br/>        self, op_handle, get_operations_resp<br/>    ):<br/>        if get_operations_resp.operationState == ttypes.TOperationState.ERROR_STATE:<br/>            if get_operations_resp.displayMessage:<br/>&gt;               raise ServerOperationError(<br/>                    get_operations_resp.displayMessage,<br/>                    {<br/>                        &quot;operation-id&quot;: op_handle and op_handle.operationId.guid,<br/>                        &quot;diagnostic-info&quot;: get_operations_resp.diagnosticInfo,<br/>                    },<br/>                )<br/><span class="error">E               databricks.sql.exc.ServerOperationError: Table or view not found: delta_bronze.prp_extrahoursapi_extrahours; line 1 pos 31</span><br/><br/>..\..\..\pdp_automation_framework\venv\lib\site-packages\databricks\sql\thrift_backend.py:526: ServerOperationError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;pdp_framework.PdpAutomation object at 0x000001B914537940&gt;<br/>t = &lt;function validations at 0x000001B914549670&gt;<br/>config = {&#x27;base_html_content&#x27;: &#x27;&lt;!DOCTYPE html&gt;\n&lt;html lang=&quot;en&quot;&gt;\n&lt;head&gt;\n    &lt;style&gt;\ntable, th, td {\n  border: 1px solid bl...e_silver_run_id&#x27;: &#x27;ad26d9b2-50ab-11ee-91b3-bcf4d42f600c&#x27;, &#x27;file&#x27;: &#x27;PRP_ExtraHoursAPI_ExtraHours_20230911-991.csv&#x27;, ...}<br/><br/>    def run_task(self, t, config):<br/>        try:<br/>&gt;           status, x_comm = t(config)<br/><br/>..\pdp_framework.py:31: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/>..\validations.py:311: in validations<br/>    status, base_html_content = run_validations(layer=layer, config=config)<br/>..\validations.py:244: in run_validations<br/>    status = count_validation(config[&quot;input_count&quot;],<br/>..\validations.py:67: in count_validation<br/>    result = run_sql_adb(query)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>query = &quot;SELECT COUNT(*) as count  FROM delta_bronze.prp_extrahoursapi_extrahours WHERE MD_PIPELINE_RUN_ID = &#x27;ad26d9b2-50ab-11ee-91b3-bcf4d42f600c&#x27; limit 1&quot;<br/><br/>    def run_sql_adb(query):<br/>        try:<br/>            azure_details_dict = get_env_vars()<br/>            adb_server_host = azure_details_dict.get(&quot;DATABRICKS_SERVER_HOSTNAME&quot;)<br/>            adb_http_path = azure_details_dict.get(&quot;DATABRICKS_HTTP_PATH&quot;)<br/>            adb_token = azure_details_dict.get(&quot;DATABRICKS_TOKEN&quot;)<br/>        except Exception as e:<br/>            logging.error(f&quot;\tEnvironment credentials are missing - {e}&quot;, exc_info=True)<br/>            raise Exception(f&quot;\tEnvironment credentials are missing - {e}&quot;)<br/>    <br/>        try:<br/>            with sql.connect(server_hostname=adb_server_host,<br/>                             http_path=adb_http_path,<br/>                             access_token=adb_token<br/>                             ) as connection:<br/>    <br/>                with connection.cursor() as cursor:<br/>                    cursor.execute(query)<br/>                    return cursor.fetchall()<br/>    <br/>        except Exception as e:<br/>            logging.error(f&quot;\tError while running Query- {e}&quot;, exc_info=True)<br/>&gt;           raise Exception(f&quot;\tError while running Query- {e}&quot;)<br/><span class="error">E           Exception: 	Error while running Query- Table or view not found: delta_bronze.prp_extrahoursapi_extrahours; line 1 pos 31</span><br/><br/>..\validations.py:27: Exception<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;pdp_framework.PdpAutomation object at 0x000001B914537940&gt;<br/><br/>    def run_pdp_flow(self):<br/>        x_comm_all = {}<br/>        for task in self.pdp_flow:<br/>            config = self.config[task]<br/>    <br/>            if self.config.get(&quot;file&quot;, None) is not None:<br/>                config[&quot;file&quot;] = self.config[&quot;file&quot;]<br/>                file_name = self.config[&quot;file&quot;]<br/>            elif config.get(&quot;file&quot;, None) is not None:<br/>                file_name = config[&quot;file&quot;]<br/>                logging.info(f&quot;\tTaking file_name from Defined Config File for task {task} is {config[&#x27;file&#x27;]}&quot;)<br/>            else:<br/>                logging.error(&quot;--file_name is neither passed in parameter nor in config json&quot;, exc_info=True)<br/>                raise Exception(&quot;\t--file_name is neither passed in parameter nor in config json&quot;)<br/>            try:<br/>                config.update(x_comm_all)<br/>                logging.info(&quot;\n\t------------------------------------------&quot;)<br/>                logging.info(f&quot;\tTASK {task.upper()} STARTED RUNNING&quot;)<br/>&gt;               status, x_comm = self.run_task(eval(task), config)<br/><br/>..\pdp_framework.py:57: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;pdp_framework.PdpAutomation object at 0x000001B914537940&gt;<br/>t = &lt;function validations at 0x000001B914549670&gt;<br/>config = {&#x27;base_html_content&#x27;: &#x27;&lt;!DOCTYPE html&gt;\n&lt;html lang=&quot;en&quot;&gt;\n&lt;head&gt;\n    &lt;style&gt;\ntable, th, td {\n  border: 1px solid bl...e_silver_run_id&#x27;: &#x27;ad26d9b2-50ab-11ee-91b3-bcf4d42f600c&#x27;, &#x27;file&#x27;: &#x27;PRP_ExtraHoursAPI_ExtraHours_20230911-991.csv&#x27;, ...}<br/><br/>    def run_task(self, t, config):<br/>        try:<br/>            status, x_comm = t(config)<br/>            if status != 0:<br/>                logging.error(f&quot;Non zero status returned from task {t} &quot;)<br/>        except Exception as e:<br/>            logging.error(f&quot;Raised error in task {t} - {e}&quot;, exc_info=True)<br/>&gt;           raise Exception(f&quot;task {t} got some error&quot;)<br/><span class="error">E           Exception: task &lt;function validations at 0x000001B914549670&gt; got some error</span><br/><br/>..\pdp_framework.py:36: Exception<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>    @pytest.mark.endtoend<br/>    # @pytest.mark.regression<br/>    def test_pdp_flow_all():<br/>        logging.info(&quot;&quot;&quot;\n\t---------------Test Description---------------<br/>        \n\tValidate ExtraHours PDP Flow, data_generator,upload_to_azure,trigger_adf_pipeline,validations\n&quot;&quot;&quot;)<br/>    <br/>        config_file = &quot;{file_prefix}_config.json&quot;.format(file_prefix=file_prefix)<br/>        config = read_config(base_folder=os.path.dirname(__file__)+&quot;..\\..\\&quot;,<br/>                             config_file=config_file)<br/>        random_number = random.randint(100, 999)<br/>        config[&quot;file&quot;] = &quot;{file_prefix}_{dt_nodash}-{random_number}.csv&quot;.format(file_prefix=file_prefix,<br/>                                                                                dt_nodash=datetime.now().strftime(&quot;%Y%m%d&quot;),<br/>                                                                                random_number=random_number)<br/>        config[&quot;pdp_flow&quot;] = [&quot;data_generator&quot;, &quot;upload_to_azure&quot;,<br/>                              &quot;trigger_adf_pipeline&quot;, &quot;validations&quot;]<br/>        config[&quot;validations&quot;][&quot;validation_flow&quot;] = [&quot;bronze&quot;, &quot;silver&quot;, &quot;gold&quot;]<br/>&gt;       status = PdpAutomation(config=config).run_pdp_flow()<br/><br/>test_pdp_flow_extrahours.py:25: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;pdp_framework.PdpAutomation object at 0x000001B914537940&gt;<br/><br/>    def run_pdp_flow(self):<br/>        x_comm_all = {}<br/>        for task in self.pdp_flow:<br/>            config = self.config[task]<br/>    <br/>            if self.config.get(&quot;file&quot;, None) is not None:<br/>                config[&quot;file&quot;] = self.config[&quot;file&quot;]<br/>                file_name = self.config[&quot;file&quot;]<br/>            elif config.get(&quot;file&quot;, None) is not None:<br/>                file_name = config[&quot;file&quot;]<br/>                logging.info(f&quot;\tTaking file_name from Defined Config File for task {task} is {config[&#x27;file&#x27;]}&quot;)<br/>            else:<br/>                logging.error(&quot;--file_name is neither passed in parameter nor in config json&quot;, exc_info=True)<br/>                raise Exception(&quot;\t--file_name is neither passed in parameter nor in config json&quot;)<br/>            try:<br/>                config.update(x_comm_all)<br/>                logging.info(&quot;\n\t------------------------------------------&quot;)<br/>                logging.info(f&quot;\tTASK {task.upper()} STARTED RUNNING&quot;)<br/>                status, x_comm = self.run_task(eval(task), config)<br/>                logging.info(f&quot;\tTASK {task.upper()}  COMPLETED&quot;)<br/>                x_comm_all.update(x_comm)<br/>            except Exception as e:<br/>&gt;               raise Exception(f&quot;\tError while Running task {task} {e}&quot;)<br/><span class="error">E               Exception: 	Error while Running task validations task &lt;function validations at 0x000001B914549670&gt; got some error</span><br/><br/>..\pdp_framework.py:61: Exception[gw0] win32 -- Python 3.9.13 C:\Users\INE12405137\PycharmProjects\pdp_automation_framework\venv\Scripts\python.exe<br/> -------------------------------Captured log call-------------------------------- <br/>test_pdp_flow_extrahours.py root INFO:12 
	---------------Test Description---------------
    
	Validate ExtraHours PDP Flow, data_generator,upload_to_azure,trigger_adf_pipeline,validations

pdp_framework.py root INFO:55 
	------------------------------------------
pdp_framework.py root INFO:56 	TASK DATA_GENERATOR STARTED RUNNING
data_generator.py root INFO:178 	Data Saved in File : PRP_ExtraHoursAPI_ExtraHours_20230911-991.csv
pdp_framework.py root INFO:58 	TASK DATA_GENERATOR  COMPLETED
pdp_framework.py root INFO:55 
	------------------------------------------
pdp_framework.py root INFO:56 	TASK UPLOAD_TO_AZURE STARTED RUNNING
upload_to_azure.py root INFO:34 	Azure Container- pdrpdata
upload_to_azure.py root INFO:45 	Source file_path  C:\Users\INE12405137\PycharmProjects\autmation_framework\pdp_automation_framework\output_data\PRP_ExtraHoursAPI_ExtraHours_20230911-991.csv
upload_to_azure.py root INFO:46 	Blob file_path  /landingzone/raw/PRP_ExtraHoursAPI_ExtraHours_20230911-991.csv
upload_to_azure.py root INFO:54 	File has been successfully uploaded to the landing zone folder.
upload_to_azure.py root INFO:80 File exist in Encrypted is  False  Location /landingzone/rawencrypted/PRP_ExtraHoursAPI_ExtraHours_20230911-991.csv
upload_to_azure.py root INFO:84 File exist in Encrypted is False Re-Checking after 5 sec
upload_to_azure.py root INFO:84 File exist in Encrypted is False Re-Checking after 5 sec
upload_to_azure.py root INFO:89 File Moved to Encrypted folder
upload_to_azure.py root INFO:95 File exist in processed is  False or error is False 
upload_to_azure.py root INFO:98 File exist in processed is  False or error is False Re-Checking after 30 sec
upload_to_azure.py root INFO:104 	File moved to processed folder. Location /landingzone/processed/PRP/ExtraHoursAPI/ExtraHours/PRP_ExtraHoursAPI_ExtraHours_20230911-991.csv
pdp_framework.py root INFO:58 	TASK UPLOAD_TO_AZURE  COMPLETED
pdp_framework.py root INFO:55 
	------------------------------------------
pdp_framework.py root INFO:56 	TASK TRIGGER_ADF_PIPELINE STARTED RUNNING
trigger_adf_pipeline.py root INFO:27 	Triggering Pipeline pl_master_orchestrator_r1dm
trigger_adf_pipeline.py root INFO:34 	Pipeline run triggered. Run ID: ad26d9b2-50ab-11ee-91b3-bcf4d42f600c
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: Succeeded 
trigger_adf_pipeline.py root INFO:27 	Triggering Pipeline pl_master_gold_with_period
trigger_adf_pipeline.py root INFO:34 	Pipeline run triggered. Run ID: af93b016-50ae-11ee-bda0-bcf4d42f600c
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: InProgress 
trigger_adf_pipeline.py root INFO:51 	Re-Checking Status after 60s
trigger_adf_pipeline.py root INFO:41 	Pipeline run status: Succeeded 
trigger_adf_pipeline.py root INFO:63 Passing x_comm values to config {&#x27;bronze_silver_run_id&#x27;: &#x27;ad26d9b2-50ab-11ee-91b3-bcf4d42f600c&#x27;, &#x27;base_html_content&#x27;: &#x27;&lt;!DOCTYPE html&gt;\n&lt;html lang=&quot;en&quot;&gt;\n&lt;head&gt;\n    &lt;style&gt;\ntable, th, td {\n  border: 1px solid black;\n}\n&lt;/style&gt;\n    &lt;meta charset=&quot;UTF-8&quot;&gt;\n    &lt;title&gt;Title&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;h1&gt;PDP Automation Report&lt;/h1&gt;\n&lt;p&gt;This is the PDP Automation report generated after the execution of PDP Automation Framework,\n    Please find the report below&lt;/p&gt;\n&lt;h2&gt;Data Generator &lt;/h2&gt;\n&lt;p&gt;Data generator Details&lt;/p&gt;\n&lt;table style=&quot;width:100%&quot;&gt;\n  &lt;tr&gt;\n    &lt;th&gt;Details&lt;/th&gt;\n    &lt;th&gt;Value&lt;/th&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td&gt;File Name&lt;/td&gt;\n    &lt;td&gt;PRP_ExtraHoursAPI_ExtraHours_20230911-991.csv&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td&gt;Generated Count&lt;/td&gt;\n    &lt;td&gt;100&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td&gt;Column Count&lt;/td&gt;\n    &lt;td&gt;11&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td&gt;Column Names&lt;/td&gt;\n    &lt;td&gt;[\&#x27;extraHourId\&#x27;, \&#x27;status\&#x27;, \&#x27;locationUuid\&#x27;, \&#x27;departmentId\&#x27;, \&#x27;assignedTo\&#x27;, \&#x27;startDateTime\&#x27;, \&#x27;endDateTime\&#x27;, \&#x27;updatedTimestamp\&#x27;, \&#x27;updatedBy\&#x27;, \&#x27;createdTimestamp\&#x27;, \&#x27;publishedTimestamp\&#x27;]&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td&gt;Status&lt;/td&gt;\n    &lt;td&gt;SUCCESS&lt;/td&gt;\n  &lt;/tr&gt;\n&lt;/table&gt;\n\n&lt;h2&gt;Upload File to Azure &lt;/h2&gt;\n&lt;p&gt;Azure Upload file details&lt;/p&gt;\n&lt;table style=&quot;width:100%&quot;&gt;\n  &lt;tr&gt;\n    &lt;th&gt;Details&lt;/th&gt;\n    &lt;th&gt;Value&lt;/th&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td&gt;Source File &lt;/td&gt;\n    &lt;td&gt;PRP_ExtraHoursAPI_ExtraHours_20230911-991.csv&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td&gt;Azure Path&lt;/td&gt;\n    &lt;td&gt;&lt;azure.storage.blob._blob_client.BlobClient object at 0x000001B9145CF190&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td&gt;Status&lt;/td&gt;\n    &lt;td&gt;SUCCESS&lt;/td&gt;\n  &lt;/tr&gt;\n&lt;/table&gt;\n\n&lt;h2&gt;Datafactory Pipeline &lt;/h2&gt;\n&lt;p&gt;Triggering datafactory pipeline details&lt;/p&gt;\n&lt;table style=&quot;width:100%&quot;&gt;\n  &lt;tr&gt;\n    &lt;th&gt;Details&lt;/th&gt;\n    &lt;th&gt;Value&lt;/th&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td&gt;ADF Pipeline Name&lt;/td&gt;\n    &lt;td&gt;pl_master_orchestrator_r1dm&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td&gt;ADF Run Id&lt;/td&gt;\n    &lt;td&gt;ad26d9b2-50ab-11ee-91b3-bcf4d42f600c&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td&gt;Status&lt;/td&gt;\n    &lt;td&gt;Succeeded&lt;/td&gt;\n  &lt;/tr&gt;\n&lt;/table&gt;\n\n&lt;h2&gt;Datafactory Pipeline &lt;/h2&gt;\n&lt;p&gt;Triggering datafactory pipeline details&lt;/p&gt;\n&lt;table style=&quot;width:100%&quot;&gt;\n  &lt;tr&gt;\n    &lt;th&gt;Details&lt;/th&gt;\n    &lt;th&gt;Value&lt;/th&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td&gt;ADF Pipeline Name&lt;/td&gt;\n    &lt;td&gt;pl_master_gold_with_period&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td&gt;ADF Run Id&lt;/td&gt;\n    &lt;td&gt;af93b016-50ae-11ee-bda0-bcf4d42f600c&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td&gt;Status&lt;/td&gt;\n    &lt;td&gt;Succeeded&lt;/td&gt;\n  &lt;/tr&gt;\n&lt;/table&gt;\n\nadd_segment\n&lt;/body&gt;\n&lt;/html&gt;&#x27;, &#x27;gold_run_id&#x27;: &#x27;af93b016-50ae-11ee-bda0-bcf4d42f600c&#x27;} and status 0
pdp_framework.py root INFO:58 	TASK TRIGGER_ADF_PIPELINE  COMPLETED
pdp_framework.py root INFO:55 
	------------------------------------------
pdp_framework.py root INFO:56 	TASK VALIDATIONS STARTED RUNNING
validations.py root INFO:310 	Running Validation for  bronze
validations.py root INFO:61 	Input Query is None
validations.py root INFO:56 	Query Generated is: SELECT COUNT(*) as count  FROM delta_bronze.prp_extrahoursapi_extrahours WHERE MD_PIPELINE_RUN_ID = &#x27;ad26d9b2-50ab-11ee-91b3-bcf4d42f600c&#x27; limit 1
validations.py root ERROR:26 	Error while running Query- Table or view not found: delta_bronze.prp_extrahoursapi_extrahours; line 1 pos 31
Traceback (most recent call last):
  File &quot;C:\Users\INE12405137\PycharmProjects\autmation_framework\pdp_automation_framework\validations.py&quot;, line 22, in run_sql_adb
    cursor.execute(query)
  File &quot;C:\Users\INE12405137\PycharmProjects\pdp_automation_framework\venv\lib\site-packages\databricks\sql\client.py&quot;, line 493, in execute
    execute_response = self.thrift_backend.execute_command(
  File &quot;C:\Users\INE12405137\PycharmProjects\pdp_automation_framework\venv\lib\site-packages\databricks\sql\thrift_backend.py&quot;, line 875, in execute_command
    return self._handle_execute_response(resp, cursor)
  File &quot;C:\Users\INE12405137\PycharmProjects\pdp_automation_framework\venv\lib\site-packages\databricks\sql\thrift_backend.py&quot;, line 967, in _handle_execute_response
    final_operation_state = self._wait_until_command_done(
  File &quot;C:\Users\INE12405137\PycharmProjects\pdp_automation_framework\venv\lib\site-packages\databricks\sql\thrift_backend.py&quot;, line 809, in _wait_until_command_done
    self._check_command_not_in_error_or_closed_state(
  File &quot;C:\Users\INE12405137\PycharmProjects\pdp_automation_framework\venv\lib\site-packages\databricks\sql\thrift_backend.py&quot;, line 526, in _check_command_not_in_error_or_closed_state
    raise ServerOperationError(
databricks.sql.exc.ServerOperationError: Table or view not found: delta_bronze.prp_extrahoursapi_extrahours; line 1 pos 31
pdp_framework.py root ERROR:35 Raised error in task &lt;function validations at 0x000001B914549670&gt; - 	Error while running Query- Table or view not found: delta_bronze.prp_extrahoursapi_extrahours; line 1 pos 31
Traceback (most recent call last):
  File &quot;C:\Users\INE12405137\PycharmProjects\autmation_framework\pdp_automation_framework\validations.py&quot;, line 22, in run_sql_adb
    cursor.execute(query)
  File &quot;C:\Users\INE12405137\PycharmProjects\pdp_automation_framework\venv\lib\site-packages\databricks\sql\client.py&quot;, line 493, in execute
    execute_response = self.thrift_backend.execute_command(
  File &quot;C:\Users\INE12405137\PycharmProjects\pdp_automation_framework\venv\lib\site-packages\databricks\sql\thrift_backend.py&quot;, line 875, in execute_command
    return self._handle_execute_response(resp, cursor)
  File &quot;C:\Users\INE12405137\PycharmProjects\pdp_automation_framework\venv\lib\site-packages\databricks\sql\thrift_backend.py&quot;, line 967, in _handle_execute_response
    final_operation_state = self._wait_until_command_done(
  File &quot;C:\Users\INE12405137\PycharmProjects\pdp_automation_framework\venv\lib\site-packages\databricks\sql\thrift_backend.py&quot;, line 809, in _wait_until_command_done
    self._check_command_not_in_error_or_closed_state(
  File &quot;C:\Users\INE12405137\PycharmProjects\pdp_automation_framework\venv\lib\site-packages\databricks\sql\thrift_backend.py&quot;, line 526, in _check_command_not_in_error_or_closed_state
    raise ServerOperationError(
databricks.sql.exc.ServerOperationError: Table or view not found: delta_bronze.prp_extrahoursapi_extrahours; line 1 pos 31

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &quot;C:\Users\INE12405137\PycharmProjects\autmation_framework\pdp_automation_framework\pdp_framework.py&quot;, line 31, in run_task
    status, x_comm = t(config)
  File &quot;C:\Users\INE12405137\PycharmProjects\autmation_framework\pdp_automation_framework\validations.py&quot;, line 311, in validations
    status, base_html_content = run_validations(layer=layer, config=config)
  File &quot;C:\Users\INE12405137\PycharmProjects\autmation_framework\pdp_automation_framework\validations.py&quot;, line 244, in run_validations
    status = count_validation(config[&quot;input_count&quot;],
  File &quot;C:\Users\INE12405137\PycharmProjects\autmation_framework\pdp_automation_framework\validations.py&quot;, line 67, in count_validation
    result = run_sql_adb(query)
  File &quot;C:\Users\INE12405137\PycharmProjects\autmation_framework\pdp_automation_framework\validations.py&quot;, line 27, in run_sql_adb
    raise Exception(f&quot;\tError while running Query- {e}&quot;)
Exception: 	Error while running Query- Table or view not found: delta_bronze.prp_extrahoursapi_extrahours; line 1 pos 31<br/></div></td></tr></tbody></table></body></html>